{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport PIL\nimport os\nimport matplotlib.pyplot as plt\n\nimport pathlib\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-13T21:48:00.712725Z","iopub.execute_input":"2022-09-13T21:48:00.713098Z","iopub.status.idle":"2022-09-13T21:48:00.720065Z","shell.execute_reply.started":"2022-09-13T21:48:00.713073Z","shell.execute_reply":"2022-09-13T21:48:00.718859Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Definindo o caminho do sistema onde os arquivos que serão analisados estão localizadas","metadata":{}},{"cell_type":"code","source":"import os.path\nimport pathlib\n\npath = '../input/simpsons-images/'\ntrain_dir = os.path.join(path,'train') \ntest_dir= os.path.join(path,'test') \ndata_dir = pathlib.Path(path)\nos.path.exists(path)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:00.729243Z","iopub.execute_input":"2022-09-13T21:48:00.729830Z","iopub.status.idle":"2022-09-13T21:48:00.743742Z","shell.execute_reply.started":"2022-09-13T21:48:00.729799Z","shell.execute_reply":"2022-09-13T21:48:00.741804Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"Visualizando uma imagem da subpasta lisa_simpson","metadata":{}},{"cell_type":"code","source":"lisa = list(data_dir.glob('test/lisa_simpson/*.jpg'))\nPIL.Image.open(str(lisa[0]))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:00.745455Z","iopub.execute_input":"2022-09-13T21:48:00.745929Z","iopub.status.idle":"2022-09-13T21:48:00.808087Z","shell.execute_reply.started":"2022-09-13T21:48:00.745904Z","shell.execute_reply":"2022-09-13T21:48:00.807293Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Visualizando uma imagem da subpasta bart_simpson","metadata":{}},{"cell_type":"code","source":"bart = list(data_dir.glob('test/bart_simpson/*.jpg'))\nPIL.Image.open(str(bart[0]))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:00.809371Z","iopub.execute_input":"2022-09-13T21:48:00.810581Z","iopub.status.idle":"2022-09-13T21:48:00.865740Z","shell.execute_reply.started":"2022-09-13T21:48:00.810525Z","shell.execute_reply":"2022-09-13T21:48:00.864309Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Convertendo a imagem no modo L para termos uma imagem de canal único e o cmap = 'cinza' converte as cores","metadata":{}},{"cell_type":"code","source":"bart = list(data_dir.glob('test/bart_simpson/*.jpg'))\nimage = PIL.Image.open(bart[0]).convert(\"L\")\nplt.imshow(image, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:00.866956Z","iopub.execute_input":"2022-09-13T21:48:00.867231Z","iopub.status.idle":"2022-09-13T21:48:01.063337Z","shell.execute_reply.started":"2022-09-13T21:48:00.867207Z","shell.execute_reply":"2022-09-13T21:48:01.061776Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Definindo o tamanho do lote de imagens que será usado e o tamanho das imagens","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nimg_height = 180\nimg_width = 180","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:01.065455Z","iopub.execute_input":"2022-09-13T21:48:01.065755Z","iopub.status.idle":"2022-09-13T21:48:01.071058Z","shell.execute_reply.started":"2022-09-13T21:48:01.065728Z","shell.execute_reply":"2022-09-13T21:48:01.069691Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"Separando o que será usado para treinamento e o que será usao para teste","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data.sampler import  SubsetRandomSampler\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  train_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:01.072666Z","iopub.execute_input":"2022-09-13T21:48:01.073349Z","iopub.status.idle":"2022-09-13T21:48:03.794715Z","shell.execute_reply.started":"2022-09-13T21:48:01.073323Z","shell.execute_reply":"2022-09-13T21:48:03.793605Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  test_dir,\n  validation_split=0.5,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:03.795851Z","iopub.execute_input":"2022-09-13T21:48:03.796836Z","iopub.status.idle":"2022-09-13T21:48:03.928384Z","shell.execute_reply.started":"2022-09-13T21:48:03.796810Z","shell.execute_reply":"2022-09-13T21:48:03.926821Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Exibindo os nomes das classes","metadata":{}},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:03.929514Z","iopub.execute_input":"2022-09-13T21:48:03.929990Z","iopub.status.idle":"2022-09-13T21:48:03.936782Z","shell.execute_reply.started":"2022-09-13T21:48:03.929963Z","shell.execute_reply":"2022-09-13T21:48:03.935489Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"Exibindo uma amostra dos dados de trainamento","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:03.938144Z","iopub.execute_input":"2022-09-13T21:48:03.938435Z","iopub.status.idle":"2022-09-13T21:48:04.933128Z","shell.execute_reply.started":"2022-09-13T21:48:03.938410Z","shell.execute_reply":"2022-09-13T21:48:04.932363Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"Visualizando a barra de cores de algumas imagens","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.colorbar()\n    plt.grid(True)\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:04.934154Z","iopub.execute_input":"2022-09-13T21:48:04.935291Z","iopub.status.idle":"2022-09-13T21:48:06.250446Z","shell.execute_reply.started":"2022-09-13T21:48:04.935252Z","shell.execute_reply":"2022-09-13T21:48:06.248911Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"Exibindo o tamanho do lote de imagem, o tamanho das imagens e os canais de cores RGB do tensor e as informações das labels","metadata":{}},{"cell_type":"code","source":"for image_batch, labels_batch in train_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:06.254096Z","iopub.execute_input":"2022-09-13T21:48:06.254404Z","iopub.status.idle":"2022-09-13T21:48:06.451904Z","shell.execute_reply.started":"2022-09-13T21:48:06.254381Z","shell.execute_reply":"2022-09-13T21:48:06.451248Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"for image_batch, labels_batch in val_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:06.453690Z","iopub.execute_input":"2022-09-13T21:48:06.454054Z","iopub.status.idle":"2022-09-13T21:48:06.904228Z","shell.execute_reply.started":"2022-09-13T21:48:06.454021Z","shell.execute_reply":"2022-09-13T21:48:06.903078Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"Dataset.cache mantém as imagens na memória depois de serem carregadas fora do disco durante a primeira época. Isso garantirá que o conjunto de dados não se torne um gargalo ao treinar o modelo\nDataset.prefetch sobrepõe o pré-processamento de dados e a execução do modelo durante o treinamento.","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:06.905482Z","iopub.execute_input":"2022-09-13T21:48:06.905846Z","iopub.status.idle":"2022-09-13T21:48:06.916186Z","shell.execute_reply.started":"2022-09-13T21:48:06.905812Z","shell.execute_reply":"2022-09-13T21:48:06.914582Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"Padronizando os valores do canal RGB para estarem no intervalo [0, 1] usando tf.keras.layers.Rescaling","metadata":{}},{"cell_type":"code","source":"normalization_layer = layers.Rescaling(1./255)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:06.917600Z","iopub.execute_input":"2022-09-13T21:48:06.918198Z","iopub.status.idle":"2022-09-13T21:48:06.942036Z","shell.execute_reply.started":"2022-09-13T21:48:06.918164Z","shell.execute_reply":"2022-09-13T21:48:06.941263Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\n# Notice the pixel values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:06.943336Z","iopub.execute_input":"2022-09-13T21:48:06.943846Z","iopub.status.idle":"2022-09-13T21:48:24.961168Z","shell.execute_reply.started":"2022-09-13T21:48:06.943813Z","shell.execute_reply":"2022-09-13T21:48:24.960240Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"Criando o modelo que possui\ntrês blocos de convolução ( tf.keras.layers.Conv2D )\numa camada de agrupamento máximo ( tf.keras.layers.MaxPooling2D ) em cada bloco\ne uma camada totalmente conectada ( tf.keras.layers.Dense ) com 128 unidades em cima dela que é ativada por uma função de ativação ReLU ( 'relu' )","metadata":{}},{"cell_type":"code","source":"num_classes = len(class_names)\n\nmodel = Sequential([\n  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:24.964246Z","iopub.execute_input":"2022-09-13T21:48:24.964589Z","iopub.status.idle":"2022-09-13T21:48:25.077661Z","shell.execute_reply.started":"2022-09-13T21:48:24.964559Z","shell.execute_reply":"2022-09-13T21:48:25.075903Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"Compilando o modelo","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:25.078883Z","iopub.execute_input":"2022-09-13T21:48:25.080388Z","iopub.status.idle":"2022-09-13T21:48:25.100875Z","shell.execute_reply.started":"2022-09-13T21:48:25.080333Z","shell.execute_reply":"2022-09-13T21:48:25.099147Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"Resumo do modelo","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:25.102343Z","iopub.execute_input":"2022-09-13T21:48:25.102664Z","iopub.status.idle":"2022-09-13T21:48:25.115700Z","shell.execute_reply.started":"2022-09-13T21:48:25.102622Z","shell.execute_reply":"2022-09-13T21:48:25.114571Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Treinando o modelo","metadata":{}},{"cell_type":"code","source":"epochs=10\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T21:48:25.117338Z","iopub.execute_input":"2022-09-13T21:48:25.117689Z","iopub.status.idle":"2022-09-13T22:08:26.030280Z","shell.execute_reply.started":"2022-09-13T21:48:25.117664Z","shell.execute_reply":"2022-09-13T22:08:26.028173Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"Gráfico de perda e precisão nos conjuntos de treinamento e validação","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T22:08:26.032424Z","iopub.execute_input":"2022-09-13T22:08:26.033127Z","iopub.status.idle":"2022-09-13T22:08:26.309514Z","shell.execute_reply.started":"2022-09-13T22:08:26.033086Z","shell.execute_reply":"2022-09-13T22:08:26.308186Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"Mudando o posicionamento da imagem para gerar \"mais imagens\" para expor o modelo a dados mais generalizados","metadata":{}},{"cell_type":"code","source":"data_augmentation = keras.Sequential(\n  [\n    layers.RandomFlip(\"horizontal\",\n                      input_shape=(img_height,\n                                  img_width,\n                                  3)),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n  ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T22:08:26.311557Z","iopub.execute_input":"2022-09-13T22:08:26.311905Z","iopub.status.idle":"2022-09-13T22:08:26.447181Z","shell.execute_reply.started":"2022-09-13T22:08:26.311879Z","shell.execute_reply":"2022-09-13T22:08:26.445331Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Visualizando as imagens geradas anteriormente","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n  for i in range(9):\n    augmented_images = data_augmentation(images)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T22:08:26.448984Z","iopub.execute_input":"2022-09-13T22:08:26.449403Z","iopub.status.idle":"2022-09-13T22:08:28.087889Z","shell.execute_reply.started":"2022-09-13T22:08:26.449377Z","shell.execute_reply":"2022-09-13T22:08:28.086639Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"Adicionando o dropout que descarta aleatoriamente um número de unidades de saída da camada durante o processo de treinamento. Quanto mais unidades desistem, mais forte é a regularização. Isso é análogo ao treinamento da rede para emular um conjunto exponencialmente grande de redes menores","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n  data_augmentation,\n  layers.Rescaling(1./255),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T22:08:28.089382Z","iopub.execute_input":"2022-09-13T22:08:28.089728Z","iopub.status.idle":"2022-09-13T22:08:28.278519Z","shell.execute_reply.started":"2022-09-13T22:08:28.089695Z","shell.execute_reply":"2022-09-13T22:08:28.277463Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"Compilando o modelo","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T22:08:28.279508Z","iopub.execute_input":"2022-09-13T22:08:28.280685Z","iopub.status.idle":"2022-09-13T22:08:28.292990Z","shell.execute_reply.started":"2022-09-13T22:08:28.280626Z","shell.execute_reply":"2022-09-13T22:08:28.291846Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"Resumo do modelo","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T22:08:28.294494Z","iopub.execute_input":"2022-09-13T22:08:28.295189Z","iopub.status.idle":"2022-09-13T22:08:28.306093Z","shell.execute_reply.started":"2022-09-13T22:08:28.295125Z","shell.execute_reply":"2022-09-13T22:08:28.304128Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"Treinando o modelo","metadata":{}},{"cell_type":"code","source":"epochs = 15\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T22:08:28.308073Z","iopub.execute_input":"2022-09-13T22:08:28.308951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizando os resultados do treinamento","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}